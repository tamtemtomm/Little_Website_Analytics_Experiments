# -*- coding: utf-8 -*-
"""MALScrape.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gbTzBU2bTPzLzRzxqY_GN-oM50nDESlf
"""

import pandas as pd
import numpy as np
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import csv

links = []
driver = webdriver.Chrome()
for page in range (0,30):
    driver.get(f'https://myanimelist.net/topanime.php?type=bypopularity&limit={page*50}')
    anime = driver.find_elements(By.TAG_NAME, 'a')
    for link in anime:
        if str(link.get_attribute('href')).startswith('https://myanimelist.net/anime/') and str(link.get_attribute('href')).split('/')[-1] != 'video':
            if str(link.get_attribute('href')) not in links:
                links.append(str(link.get_attribute('href')))

with open('Links.txt', 'w') as f:
    for link in links:
        f.write(f'{link}\n')
    print('Done')

links = []
with open('Links.txt', 'r') as f:
    file = f.read()
for link in file.split('\n'):
    links.append(link)
links = links[1:]

data = []
driver = webdriver.Chrome()
for link in links:
    driver.get(link)
    title = driver.find_element(By.CSS_SELECTOR, 'h1[class="title-name h1_bold_none"]').text

    rank = driver.find_element(By.CSS_SELECTOR, 'span[class="numbers ranked"]').text.split()[-1][1:]

    rating = driver.find_element(By.CSS_SELECTOR, 'span[itemprop="ratingValue"]').text

    popularity = driver.find_element(By.CSS_SELECTOR, 'span[class="numbers popularity"]').text.split()[-1][1:]

    members = driver.find_element(By.CSS_SELECTOR, 'span[class="numbers members"]').text.split()[-1].replace(',','')

    try : types = driver.find_element(By.XPATH, '//*[contains(text(), "Type:")]/parent::div/a').text
    except : types = driver.find_element(By.XPATH, '//*[contains(text(), "Type:")]/parent::div').text.split(':')[-1].strip()

    episode = driver.find_element(By.XPATH, '//*[contains(text(), "Episodes:")]/parent::div').text.split()[-1]

    status = driver.find_elements(By.XPATH, '//*[contains(text(), "Status:")]/parent::div')[1].text.split(':')[-1].strip()

    aired = driver.find_elements(By.XPATH, '//*[contains(text(), "Aired:")]/parent::div')[1].text.split(':')[-1].lstrip()

    try:premiered = driver.find_element(By.XPATH, '//*[contains(text(), "Premiered:")]/parent::div/a').text
    except:premiered = np.nan

    producerss = driver.find_elements(By.XPATH, '//*[contains(text(), "Producers:")]/parent::div/a')
    producers = [producer.text for producer in producerss]

    licensor = driver.find_element(By.XPATH, '//*[contains(text(), "Licensors:")]/parent::div/a').text

    studio = driver.find_element(By.XPATH, '//*[contains(text(), "Studios:")]/parent::div/a').text

    source = driver.find_element(By.XPATH, '//*[contains(text(), "Source:")]/parent::div').text.split()[-1]

    genress = driver.find_elements(By.XPATH, '//*[contains(text(), "Genres:")]/parent::div/a')
    genres = [genre.text for genre in genress]

    try:theme = driver.find_element(By.XPATH, '//*[contains(text(), "Theme:")]/parent::div/a').text
    except:theme = np.nan

    try:demographic = driver.find_element(By.XPATH, '//*[contains(text(), "Demographic:")]/parent::div/a').text
    except:demographic = np.nan

    duration = driver.find_element(By.XPATH, '//*[contains(text(), "Duration:")]/parent::div').text.split(':')[-1].strip()

    age = driver.find_element(By.XPATH, '//*[contains(text(), "Rating:")]/parent::div').text.split(':')[-1].strip()

    favorites = int(driver.find_elements(By.XPATH, '//*[contains(text(), "Favorites:")]/parent::div')[1].text.split(':')[-1].strip().replace(',',''))

    data.append([title, rank, rating, popularity, members, types, episode, status, aired, premiered, producers, licensor, studio, source, genres, theme, demographic, duration, age, favorites])

# driver = webdriver.Chrome()
# driver.get('https://myanimelist.net/anime/34240/Shelter_Music')
# driver.find_element(By.XPATH, '//*[contains(text(), "Rating:")]/parent::div').text.split(':')[-1].strip()

with open('Anime.csv', 'w') as f:
    writer = csv.writer(f)
    for anime in data:
        writer.writerow(anime)
# title,rank,rating,popularity,members,types,episode,status,aired,premiered,producers,licensor,studio,source,genres,theme,demographic,duration,age,favorites

df = pd.read_csv('Anime.csv')

df.producers[0]